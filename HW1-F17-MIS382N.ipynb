{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# <p style=\"text-align: center;\">MIS 382N: ADVANCED PREDICTIVE MODELING - MSBA</p>\n",
    "# <p style=\"text-align: center;\">Assignment 1</p>\n",
    "## <p style=\"text-align: center;\">Total points: 75</p>\n",
    "## <p style=\"text-align: center;\">Due: Tuesday, September 13 submitted via Canvas by 11:59 p</p>\n",
    "\n",
    "Your homework should be written in a **Jupyter notebook**. You may work in groups of two if you wish. Only one student per team needs to submit the assignment on Canvas.  But be sure to include name and UTEID for both students.  Homework groups will be created and managed through Canvas, so please do not arbitrarily change your homework group.  \n",
    "\n",
    "Also, please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Applications of machine learning (10 pts)\n",
    "\n",
    "Read the [article](http://www.datasciencecentral.com/profiles/blogs/20-data-science-systems-used-by-amazon-to-operate-its-business) \"21 data science systems used by Amazon to operate its business\" and pick any two of the data science systems used by Amazon according to this blog.\n",
    "\n",
    "(5 pts each) For each of these two system you have chosen:\n",
    "\n",
    "What kind of machine learning problem is involved (e.g. classification, regression, clustering, outlier detection,...)? Speculate on what kind of data may be needed and how the results can be useful to the company.\n",
    "\n",
    "\n",
    "## Answer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Maximum likelihood estimate (10 pts)\n",
    "\n",
    "Suppose a manager at an internet sales company wants to estimate how fast his salesperson is generating successful leads. Instead of recording the time for each lead, the time taken to generate the next 5 leads are recorded, i.e., there is one recording (denoting the elapsed time) for every 5 consecutive leads. For a specific salesperson, the time intervals recorded are {1,3,1.5,4,2,7,1.2,2,4,3.1} hours. \n",
    "\n",
    "A statistician suggests that if these time intervals are assumed to arise by i.i.d. sampling from the following distribution:\n",
    "$$ p(t) = \\frac{1}{C \\times \\theta^{5}}t^{4}exp^{-\\frac{t}{\\theta}},$$\n",
    "(where C is a normalizing constant). Therefore, if $\\theta$ can be estimated, then he can provide detailed information\n",
    "about the lead generation process, including average rates, variances etc.\n",
    "\n",
    "Find the Maximum Likelihood estimate for $\\theta$ based on the recorded observations.\n",
    "\n",
    "\n",
    "## Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log[p(t|theta)] = sum from i to n of: -log[C]-5log[theta]+4log[t]-t/theta\n",
    "derivative wrt t =0\n",
    "-5/theta +(sum from i to n of:t(i))/theta^2 = 0\n",
    "theta = (sum from i to n of:t(i))/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.76"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals = [1,3,1.5,4,2,7,1.2,2,4,3.1]\n",
    "sum(intervals)/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Multiple Linear Regression in Python (25 pts)\n",
    "\n",
    "Use the following code to import the boston housing dataset and linear models in python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Reeddalton/anaconda/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%pylab inline\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows is: 506\n",
      "Number of columns is: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  6.32000000e-03,   1.80000000e+01,   2.31000000e+00,\n",
       "          0.00000000e+00,   5.38000000e-01,   6.57500000e+00,\n",
       "          6.52000000e+01,   4.09000000e+00,   1.00000000e+00,\n",
       "          2.96000000e+02,   1.53000000e+01,   3.96900000e+02,\n",
       "          4.98000000e+00],\n",
       "       [  2.73100000e-02,   0.00000000e+00,   7.07000000e+00,\n",
       "          0.00000000e+00,   4.69000000e-01,   6.42100000e+00,\n",
       "          7.89000000e+01,   4.96710000e+00,   2.00000000e+00,\n",
       "          2.42000000e+02,   1.78000000e+01,   3.96900000e+02,\n",
       "          9.14000000e+00],\n",
       "       [  2.72900000e-02,   0.00000000e+00,   7.07000000e+00,\n",
       "          0.00000000e+00,   4.69000000e-01,   7.18500000e+00,\n",
       "          6.11000000e+01,   4.96710000e+00,   2.00000000e+00,\n",
       "          2.42000000e+02,   1.78000000e+01,   3.92830000e+02,\n",
       "          4.03000000e+00],\n",
       "       [  3.23700000e-02,   0.00000000e+00,   2.18000000e+00,\n",
       "          0.00000000e+00,   4.58000000e-01,   6.99800000e+00,\n",
       "          4.58000000e+01,   6.06220000e+00,   3.00000000e+00,\n",
       "          2.22000000e+02,   1.87000000e+01,   3.94630000e+02,\n",
       "          2.94000000e+00],\n",
       "       [  6.90500000e-02,   0.00000000e+00,   2.18000000e+00,\n",
       "          0.00000000e+00,   4.58000000e-01,   7.14700000e+00,\n",
       "          5.42000000e+01,   6.06220000e+00,   3.00000000e+00,\n",
       "          2.22000000e+02,   1.87000000e+01,   3.96900000e+02,\n",
       "          5.33000000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3a\n",
    "row , col = X.shape\n",
    "print \"Number of rows is:\" , row\n",
    "print \"Number of columns is:\" , col\n",
    "X[:5,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() takes at least 3 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-83fda7af2551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Train the model using the training sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() takes at least 3 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "#3b\n",
    "regr = linear_model.LinearRegression()\n",
    "# Train the model using the training sets\n",
    "regr.fit(X)\n",
    "regr.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ -1.91246374e-01   4.42289967e-02   5.52207977e-02   1.71631351e+00\n",
      "  -1.49957220e+01   4.88773025e+00   2.60921031e-03  -1.29480799e+00\n",
      "   4.84787214e-01  -1.54006673e-02  -8.08795026e-01  -1.29230427e-03\n",
      "  -5.17953791e-01]\n",
      "Mean squared error: 38.1643386432\n"
     ]
    }
   ],
   "source": [
    "#3c\n",
    "test_set_size = 400\n",
    "X_mlr_train = X[:test_set_size,]\n",
    "X_mlr_test = X[test_set_size:,]\n",
    "y_mlr_train = y[:test_set_size]\n",
    "y_mlr_test = y[test_set_size:]\n",
    "regr_split = linear_model.LinearRegression()\n",
    "regr_split.fit(X_mlr_train, y_mlr_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_mlr_pred = regr_split.predict(X_mlr_test)\n",
    "# The coefficients\n",
    "print 'Coefficients:', regr_split.coef_\n",
    "# The mean squared error\n",
    "print \"Mean squared error:\" , mean_squared_error(y_mlr_test, y_mlr_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset information can be found [here](http://scikit-learn.org/stable/datasets/index.html#boston-house-prices-dataset).\n",
    "\n",
    "a. (3 pts) Print the shape (number of rows and columns) of the feature matrix, and print the first 5 rows.\n",
    "\n",
    "b.  (6 pts) Using ordinary least squares, fit a multiple linear regression (MLR) on all the feature variables using the entire dataset (506 rows). Report the regression coefficient of each input feature and evaluate the model using mean squared error (MSE).  Example of ordinary least squares in Python is shown in Section 1.1.1 of http://scikit-learn.org/stable/modules/linear_model.html.\n",
    "\n",
    "c.  (6 pts) Split the data into a training set and a test set.  Use the first 400 rows for training set and remaining rows for test set.  Fit an MLR using the training set.  Evaluate the trained model using the training set and the test set, respectively.  Compare the two MSE values thus obtained.\n",
    "\n",
    "d.  (6 pts) Do you think your MLR model is reasonable for this problem? You may look at the distribution of residuals to provide an informed answer.\n",
    "\n",
    "e. (5 pts) Use the following code to add new features to the dataset.  You should have 26 variables now.  Note that this code adds one squared term for each variable; in practice one may introduce only a few terms based on domain knowledge or experimentation.  Repeat (c) and report the MSE values of the training set and the test set, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_new = np.concatenate((X, np.square(X)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [ -6.28564029e-01  -4.69283413e-02   1.35998008e-01   1.12670518e+00\n",
      "  -3.89085940e+01  -1.71470367e+01  -1.92714017e-02  -2.49211073e+00\n",
      "   6.85468872e-01  -1.10900553e-01  -6.25152381e+00   4.25358263e-02\n",
      "  -1.43915460e+00   5.03672853e-03   5.35234383e-04  -4.91394588e-03\n",
      "   1.12670518e+00   1.11228197e+01   1.61544902e+00   2.97952872e-04\n",
      "   1.37189224e-01  -3.37949389e-02   1.47365245e-04   1.54711150e-01\n",
      "  -7.67778717e-05   2.70068424e-02]\n",
      "Mean squared error: 32.9465487203\n"
     ]
    }
   ],
   "source": [
    "#3e\n",
    "X_new_mlr_train = X_new[:test_set_size,]\n",
    "X_new_mlr_test = X_new[test_set_size:,]\n",
    "y_mlr_train = y[:test_set_size]\n",
    "y_mlr_test = y[test_set_size:]\n",
    "regr_split = linear_model.LinearRegression()\n",
    "regr_split.fit(X_new_mlr_train, y_mlr_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_mlr_pred = regr_split.predict(X_new_mlr_test)\n",
    "# The coefficients\n",
    "print 'Coefficients:', regr_split.coef_\n",
    "# The mean squared error\n",
    "print \"Mean squared error:\" , mean_squared_error(y_mlr_test, y_mlr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Ridge and Lasso Regression (25 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same boston data from before, in this question you will explore the application of Lasso and Ridge regression using sklearn package in Python. The following code will split the data into training and test set using [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) with **random state 20** and **test_size = 0.33**.  Note: lambda is called alpha in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.33, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Use sklearn.linear_model.Lasso and sklearn.linear_model.Ridge classes to do a [5-fold cross validation](http://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#example-exercises-plot-cv-diabetes-py) using sklearn's [KFold](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html). For the sweep of the regularization parameter, we will look at a grid of values ranging from $\\lambda = 10^{10}$ to $\\lambda = 10^{-2}$. In Python, you can consider this range of values as follows:\n",
    "\n",
    "      import numpy as np\n",
    "\n",
    "      alphas =  10**np.linspace(10,-2,100)*0.5\n",
    "\n",
    "  Report the best chosen $\\lambda$ based on cross validation. The cross validation should happen on your training data using  average MSE as the scoring metric. (8pts)\n",
    "\n",
    "2) Run ridge and lasso for all of the alphas specified above (on training data), and plot the coefficients learned for each of them - there should be one plot each for lasso and ridge, so a total of two plots; the plots for different features for a method should be on the same plot (e.g. Fig 6.6 of JW). What do you qualitatively observe when value of the regularization parameter is changed? (7pts)\n",
    "\n",
    "3) Run least squares regression, ridge, and lasso on the training data. For ridge and lasso, use only the best regularization parameter. Report the prediction error (MSE) on the test data for each. (5pts)\n",
    "\n",
    "4) Run lasso again with cross validation using [sklearn.linear_model.LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html). Set the cross validation parameters as follows:\n",
    "\n",
    "    LassoCV(alphas=None, cv=10, max_iter=10000)\n",
    "\n",
    "Report the best $\\lambda$ based on cross validation. Run lasso on the training data using the best $\\lambda$ and report the coefficeints for 26 variables. What do you observe from these coefficients? (5pts)\n",
    "\n",
    "## Answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5  (5 pts)\n",
    "\n",
    "A regression model that includes \"interaction terms\" (i.e. quadratic terms of the form $x_ix_j$) as predictors in addition to the linear terms is clearly more general than a corresponding model that employs the same independent variables but only uses the linear terms. Outline two situations where the simpler (less general) model would be preferred to the more powerful model that includes interactive terms.\n",
    "\n",
    "## Answer\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
